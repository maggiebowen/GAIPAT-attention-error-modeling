{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36ab5a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Testing participant: 87891249\n",
      "[INFO] Testing figure: sc\n",
      "[SUCCESS] Loaded screen gaze: (4525, 3)\n",
      "[SUCCESS] Loaded table gaze: (3432, 3)\n",
      "[INFO] Loaded pupil data: (533, 6)\n",
      "[INFO] Loaded screen events and states\n",
      "[INFO] Loaded table events and states\n",
      "       timestamp   x   y\n",
      "0  1706261126399 NaN NaN\n",
      "1  1706261126410 NaN NaN\n",
      "2  1706261126420 NaN NaN\n",
      "3  1706261126432 NaN NaN\n",
      "4  1706261126443 NaN NaN\n",
      "       timestamp         x         y\n",
      "0  1706261126399  0.345623  0.728385\n",
      "1  1706261126417  0.343288  0.725673\n",
      "2  1706261126435  0.339605  0.725688\n",
      "3  1706261126448  0.336395  0.721700\n",
      "4  1706261126466       NaN       NaN\n",
      "         timestamp  confidence_right  confidence_left  diameter_right  \\\n",
      "449  1706261131918                 1                1        4.481079   \n",
      "450  1706261131927                 1                1        4.499557   \n",
      "451  1706261131938                 1                1        4.486954   \n",
      "452  1706261131950                 1                1        4.486954   \n",
      "453  1706261131960                 1                1        4.476959   \n",
      "\n",
      "     diameter_left  diameter_z  \n",
      "449       4.262070    1.576291  \n",
      "450       4.275177    1.644447  \n",
      "451       4.254776    1.597959  \n",
      "452       4.261536    1.597959  \n",
      "453       4.251907    1.561096  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "def load_participant_figure_data(base_dir, participant_id=None, figure_name=None) -> dict:\n",
    "    participants = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    participant_id = participants[0] if participants else None\n",
    "\n",
    "    if not participant_id:\n",
    "        raise RuntimeError(\"No participant folders found.\")\n",
    "\n",
    "    print(f\"[INFO] Testing participant: {participant_id}\")\n",
    "    participant_path = os.path.join(base_dir, participant_id)\n",
    "    figure_names = [d for d in os.listdir(participant_path) if os.path.isdir(os.path.join(participant_path, d))]\n",
    "\n",
    "    if not figure_names:\n",
    "        raise RuntimeError(f\"No figure folders found for {participant_id}\")\n",
    "    \n",
    "    figure_name = figure_names[0]\n",
    "    print(f\"[INFO] Testing figure: {figure_name}\")\n",
    "\n",
    "    # Paths\n",
    "    fig_path = os.path.join(participant_path, figure_name)\n",
    "    screen_path = os.path.join(fig_path, 'screen')\n",
    "    table_path = os.path.join(fig_path, 'table')\n",
    "\n",
    "    # Load gaze data\n",
    "    df_screen = pd.read_csv(os.path.join(screen_path, 'gazepoints.csv'))\n",
    "    df_table = pd.read_csv(os.path.join(table_path, 'gazepoints.csv'))\n",
    "    print(f\"[SUCCESS] Loaded screen gaze: {df_screen.shape}\")\n",
    "    print(f\"[SUCCESS] Loaded table gaze: {df_table.shape}\")\n",
    "\n",
    "    # Load pupil data (required)\n",
    "    pupil_path = os.path.join(screen_path, 'pupil_info.csv')\n",
    "    if not os.path.exists(pupil_path):\n",
    "        raise FileNotFoundError(f\"[ERROR] Missing pupil_info.csv for {participant_id} â†’ {figure_name}\")\n",
    "    \n",
    "    pupil_df = pd.read_csv(pupil_path)\n",
    "    pupil_df = pupil_df.dropna(subset=['timestamp', 'diameter_right'])\n",
    "    mean_d = pupil_df['diameter_right'].mean()\n",
    "    std_d = pupil_df['diameter_right'].std()\n",
    "    pupil_df['diameter_z'] = (pupil_df['diameter_right'] - mean_d) / std_d\n",
    "    print(f\"[INFO] Loaded pupil data: {pupil_df.shape}\")\n",
    "\n",
    "    # Load screen events and states\n",
    "    try:\n",
    "        screen_events = pd.read_csv(os.path.join(screen_path, 'events.csv'))\n",
    "        screen_states = pd.read_csv(os.path.join(screen_path, 'states.csv'))\n",
    "        print(\"[INFO] Loaded screen events and states\")\n",
    "    except Exception as e:\n",
    "        screen_events, screen_states = None, None\n",
    "        print(f\"[WARNING] Could not load screen events/states: {e}\")\n",
    "\n",
    "    # Load table events and states\n",
    "    try:\n",
    "        table_events = pd.read_csv(os.path.join(table_path, 'events.csv'))\n",
    "        table_states = pd.read_csv(os.path.join(table_path, 'states.csv'))\n",
    "        print(\"[INFO] Loaded table events and states\")\n",
    "    except Exception as e:\n",
    "        table_events, table_states = None, None\n",
    "        print(f\"[WARNING] Could not load table events/states: {e}\")\n",
    "\n",
    "    return {\n",
    "        'participant_id': participant_id,\n",
    "        'figure_name': figure_name,\n",
    "        'df_screen': df_screen,\n",
    "        'df_table': df_table,\n",
    "        'pupil_df': pupil_df,\n",
    "        'screen_events': screen_events,\n",
    "        'screen_states': screen_states,\n",
    "        'table_events': table_events,\n",
    "        'table_states': table_states\n",
    "    }\n",
    "\n",
    "data = load_participant_figure_data(\"gaipat_data/participants\")\n",
    "df_screen = data['df_screen']\n",
    "df_table = data['df_table']\n",
    "pupil_df = data['pupil_df']\n",
    "\n",
    "# check if it works\n",
    "print(df_screen.head())\n",
    "print(df_table.head())\n",
    "print(pupil_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d674ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preprocess_gaze(df_screen, df_table) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges and preprocesses gaze data from screen and table into a single dataframe.\n",
    "    - add source column\n",
    "    - drop NaN\n",
    "    - convert to seconds\n",
    "    - sort by timestamp\n",
    "    \"\"\"\n",
    "\n",
    "    # assign source labels\n",
    "    df_screen['source'] = 'screen'\n",
    "    df_table['source'] = 'table'\n",
    "\n",
    "    # drop NaN, specifying columns in abundance of caution\n",
    "    df_screen = df_screen.dropna(subset=['x', 'y', 'timestamp'])\n",
    "    df_table = df_table.dropna(subset=['x', 'y', 'timestamp'])\n",
    "\n",
    "    # merge dataframes\n",
    "    df = pd.concat([df_screen, df_table], ignore_index=True)\n",
    "\n",
    "    # sort by timestamp\n",
    "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_merged = merge_preprocess_gaze(df_screen, df_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce80884a",
   "metadata": {},
   "source": [
    "### Gaze Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0aba269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      start_time       end_time   entropy\n",
      "0  1706261126399  1706261128399  3.489089\n",
      "1  1706261126899  1706261128899  3.360848\n",
      "2  1706261127399  1706261129399  2.654981\n",
      "3  1706261127899  1706261129899  2.052651\n",
      "4  1706261128399  1706261130399  2.584189\n"
     ]
    }
   ],
   "source": [
    "def calc_gaze_entropy(xy_points, bins=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate spatial entropy of gaze data.\n",
    "    Shannon entropy quantifies how unpredictable the location of a point is based on its x and y values\n",
    "\n",
    "    Parameters:\n",
    "        xy_points (np.ndarray): 2D array of shape (N, 2) for gaze coordinates\n",
    "        bins (int): number of bins per axis for histogram\n",
    "    Returns:\n",
    "        float: Shannon entropy in bits\n",
    "    \"\"\"\n",
    "    if xy_points.shape[0] < 2:\n",
    "        return np.nan  # when there's not enough data to compute entropy\n",
    "\n",
    "    # 2D histogram over gaze space\n",
    "    H, _, _ = np.histogram2d(xy_points[:, 0], xy_points[:, 1], bins=bins)\n",
    "\n",
    "    # Flatten and normalize to get probabilities\n",
    "    p = H.flatten() / np.sum(H)\n",
    "    # remove zero bins to avoid log(0)\n",
    "    p = p[p > 0]  \n",
    "\n",
    "    # compute Shannon entropy in bits\n",
    "    return entropy(p, base=2)\n",
    "\n",
    "# calculating entropy in 2 second chunks (2000 ms) with 500 ms steps\n",
    "def compute_entropy_over_time(df, window_size=2000, step_size=500, bins=10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Slides a time window over gaze data and computes spatial entropy per window.\n",
    "    Returns a DataFrame with: start_time, end_time, entropy\n",
    "    helps understand how gaze patterns change over time\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    start_time = df['timestamp'].min()\n",
    "    end_time = df['timestamp'].max()\n",
    "    current = start_time\n",
    "\n",
    "    while current + window_size <= end_time:\n",
    "        window = df[(df['timestamp'] >= current) & (df['timestamp'] < current + window_size)]\n",
    "        if len(window) >= 2:\n",
    "            xy = window[['x', 'y']].to_numpy()\n",
    "            ent = calc_gaze_entropy(xy, bins=bins)\n",
    "            results.append({\n",
    "                'start_time': current,\n",
    "                'end_time': current + window_size,\n",
    "                'entropy': ent\n",
    "            })\n",
    "        current += step_size\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "entropy_df = compute_entropy_over_time(df_merged)\n",
    "\n",
    "# check it worked\n",
    "print(entropy_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7441707",
   "metadata": {},
   "source": [
    "Setting thresholds, 3 distraction levels (could make it more in the future if we have more physiological signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62707fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      start_time       end_time   entropy  distraction_level\n",
      "0  1706261126399  1706261128399  3.489089                  2\n",
      "1  1706261126899  1706261128899  3.360848                  1\n",
      "2  1706261127399  1706261129399  2.654981                  0\n",
      "3  1706261127899  1706261129899  2.052651                  0\n",
      "4  1706261128399  1706261130399  2.584189                  0\n"
     ]
    }
   ],
   "source": [
    "# split into quartiles, we want 3 attention categories: low, medium, high\n",
    "thresholds = entropy_df['entropy'].quantile([1/3, 2/3]).values\n",
    "\n",
    "# Bin entropy values into distraction levels\n",
    "entropy_df['distraction_level'] = pd.cut(\n",
    "    entropy_df['entropy'],\n",
    "    bins=[-np.inf, thresholds[0], thresholds[1], np.inf],\n",
    "    labels=[0, 1, 2],\n",
    "    include_lowest=True\n",
    ").astype(int)\n",
    "\n",
    "# check if it worked\n",
    "print(entropy_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dda910",
   "metadata": {},
   "source": [
    "### Pupil Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9af12605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pupil_data(pupil_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drops low-confidence or missing samples and normalizes diameter within-participant.\n",
    "    \"\"\"\n",
    "    # drops missing/invalid values\n",
    "    pupil_df = pupil_df.dropna(subset=['timestamp', 'diameter_right', 'confidence_right'])\n",
    "\n",
    "    # filter by confidence threshold, if exists\n",
    "    if 'confidence_right' in pupil_df.columns:\n",
    "        pupil_df = pupil_df[pupil_df['confidence_right'] >= 0.6]\n",
    "\n",
    "    # Normalize diameter (z-score)\n",
    "    mean_d = pupil_df['diameter_right'].mean()\n",
    "    std_d = pupil_df['diameter_right'].std()\n",
    "    pupil_df['diameter_z'] = (pupil_df['diameter_right'] - mean_d) / std_d\n",
    "\n",
    "    return pupil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pupil_features(entropy_df, pupil_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes mean and std of pupil diameter (z-scored) per entropy window.\n",
    "    Adds valid sample ratio as a quality metric.\n",
    "    \"\"\"\n",
    "    means, stds, valid_ratios = [], [], []\n",
    "\n",
    "    for _, row in entropy_df.iterrows():\n",
    "        start, end = row['start_time'], row['end_time']\n",
    "        window = pupil_df[(pupil_df['timestamp'] >= start) & (pupil_df['timestamp'] < end)]\n",
    "\n",
    "        if len(window) == 0:\n",
    "            means.append(np.nan)\n",
    "            stds.append(np.nan)\n",
    "            valid_ratios.append(0.0)\n",
    "        else:\n",
    "            means.append(window['diameter_z'].mean())\n",
    "            stds.append(window['diameter_z'].std())\n",
    "            # pupil_valid_ratio = number of pupil samples in window / (window duration in milliseconds)\n",
    "            valid_ratios.append(len(window) / (end - start))  # samples per ms\n",
    "\n",
    "    entropy_df['pupil_mean'] = means\n",
    "    entropy_df['pupil_std'] = stds\n",
    "    entropy_df['pupil_valid_ratio'] = valid_ratios\n",
    "\n",
    "    return entropy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      start_time       end_time   entropy  distraction_level  pupil_mean  \\\n",
      "0  1706261126399  1706261128399  3.489089                  2         NaN   \n",
      "1  1706261126899  1706261128899  3.360848                  1         NaN   \n",
      "2  1706261127399  1706261129399  2.654981                  0         NaN   \n",
      "3  1706261127899  1706261129899  2.052651                  0         NaN   \n",
      "4  1706261128399  1706261130399  2.584189                  0         NaN   \n",
      "\n",
      "   pupil_std  pupil_valid_ratio  \n",
      "0        NaN                0.0  \n",
      "1        NaN                0.0  \n",
      "2        NaN                0.0  \n",
      "3        NaN                0.0  \n",
      "4        NaN                0.0  \n",
      "[PUPIL] range: 1706261131918 â†’ 1706261182072\n",
      "[ENTROPY] range: 1706261126399 â†’ 1706261181899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>pupil_mean</th>\n",
       "      <th>pupil_valid_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1706261175399</td>\n",
       "      <td>1706261177399</td>\n",
       "      <td>-0.108267</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1706261175899</td>\n",
       "      <td>1706261177899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1706261176399</td>\n",
       "      <td>1706261178399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1706261176899</td>\n",
       "      <td>1706261178899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1706261177399</td>\n",
       "      <td>1706261179399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1706261177899</td>\n",
       "      <td>1706261179899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1706261178399</td>\n",
       "      <td>1706261180399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1706261178899</td>\n",
       "      <td>1706261180899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1706261179399</td>\n",
       "      <td>1706261181399</td>\n",
       "      <td>-0.116332</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1706261179899</td>\n",
       "      <td>1706261181899</td>\n",
       "      <td>-0.166275</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_time       end_time  pupil_mean  pupil_valid_ratio\n",
       "98   1706261175399  1706261177399   -0.108267              0.006\n",
       "99   1706261175899  1706261177899         NaN              0.000\n",
       "100  1706261176399  1706261178399         NaN              0.000\n",
       "101  1706261176899  1706261178899         NaN              0.000\n",
       "102  1706261177399  1706261179399         NaN              0.000\n",
       "103  1706261177899  1706261179899         NaN              0.000\n",
       "104  1706261178399  1706261180399         NaN              0.000\n",
       "105  1706261178899  1706261180899         NaN              0.000\n",
       "106  1706261179399  1706261181399   -0.116332              0.014\n",
       "107  1706261179899  1706261181899   -0.166275              0.035"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now add pupil features to entropy_df\n",
    "entropy_df = compute_pupil_features(entropy_df, pupil_df)\n",
    "\n",
    "# testing to see if its working, some are NaN but maybe no pupil data in that window\n",
    "print(entropy_df.head())\n",
    "print(\"[PUPIL] range:\", pupil_df['timestamp'].min(), \"â†’\", pupil_df['timestamp'].max())\n",
    "print(\"[ENTROPY] range:\", entropy_df['start_time'].min(), \"â†’\", entropy_df['end_time'].max())\n",
    "entropy_df[['start_time', 'end_time', 'pupil_mean', 'pupil_valid_ratio']].tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974570d",
   "metadata": {},
   "source": [
    "Prep data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0842ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       start_time       end_time   entropy  distraction_level  pupil_mean  \\\n",
      "8   1706261130399  1706261132399  3.490442                  2    1.464984   \n",
      "9   1706261130899  1706261132899  3.585266                  2    1.464984   \n",
      "10  1706261131399  1706261133399  3.472622                  2    1.464984   \n",
      "11  1706261131899  1706261133899  3.296836                  1    1.464984   \n",
      "24  1706261138399  1706261140399  2.369924                  0    1.065059   \n",
      "\n",
      "    pupil_std  pupil_valid_ratio  \n",
      "8    0.156792             0.0090  \n",
      "9    0.156792             0.0090  \n",
      "10   0.156792             0.0090  \n",
      "11   0.156792             0.0090  \n",
      "24   0.280486             0.0165  \n"
     ]
    }
   ],
   "source": [
    "# define features to train model on\n",
    "features = ['entropy', 'pupil_mean', 'pupil_std', 'pupil_valid_ratio']\n",
    "# define target variable\n",
    "target = 'distraction_level'\n",
    "\n",
    "# drop all NaNs, based on features defined above\n",
    "train_df = entropy_df.dropna(subset=features + [target])\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38401c98",
   "metadata": {},
   "source": [
    "### Train\n",
    "#### Naive Bayes and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1db7ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        12\n",
      "           1       1.00      0.76      0.87        17\n",
      "           2       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.89        46\n",
      "   macro avg       0.90      0.90      0.89        46\n",
      "weighted avg       0.91      0.89      0.89        46\n",
      "\n",
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        12\n",
      "           1       0.73      0.65      0.69        17\n",
      "           2       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.79      0.79      0.78        46\n",
      "weighted avg       0.78      0.78      0.78        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "features = ['entropy', 'pupil_mean', 'pupil_std', 'pupil_valid_ratio']\n",
    "X = train_df[features]\n",
    "y = train_df['distraction_level']\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "y_pred_nb = cross_val_predict(nb, X, y, cv=5)\n",
    "print(\"Naive Bayes:\")\n",
    "print(classification_report(y, y_pred_nb))\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "y_pred_lr = cross_val_predict(lr, X, y, cv=5)\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe1b22b",
   "metadata": {},
   "source": [
    "Given that Naive Bayes performs slightly better, let's train the whole model on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5cda34e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model saved to naive_bayes_distraction_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# train on the full dataset now\n",
    "final_nb = GaussianNB()\n",
    "final_nb.fit(X, y)\n",
    "\n",
    "# save model\n",
    "joblib.dump(final_nb, \"naive_bayes_distraction_model.joblib\")\n",
    "print(\"[INFO] Model saved to naive_bayes_distraction_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7898d1",
   "metadata": {},
   "source": [
    "Note to self for later to improve model performance:\n",
    "- add pupil info for better means of interpreting cognitive state via pupil dilation\n",
    "- add AOIs for both screen and table (need to calculate from slides provided)\n",
    "- Add events.csv logic to: Track task steps, extract errors or redundant actions, add task_phase, action_count, or task_efficiency features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
